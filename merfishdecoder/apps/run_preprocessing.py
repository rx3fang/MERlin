import os
import pickle
import pandas as pd
import numpy as np
from scipy import stats, special

from merfishdecoder.core import zplane
from merfishdecoder.util import imagefilter
from merfishdecoder.util import preprocessing
from merfishdecoder.util import utilities

def run_job(dataSetName: str = None,
            fov: int = None,
            zpos: float = None,
            warpedImagesName: str = None,
            outputName: str = None,
            highPassFilterSigma: int = 3,
<<<<<<< HEAD
            lowPassFilterSigma: int = 1):
=======
            scaleFactorFile: str = None,
            logTransform: bool = False):
>>>>>>> c1e3ee130d7256ac122fa56c033538dda702739b

    
    """
    Preprocessing of MERFISH images prior to decoding:
<<<<<<< HEAD
        1) remove cell background - when highPassFilter is True
        2) normalize magnitude
        3) add gussian blur - when lowPassFilterSigma is True
    
=======
        1) remove cell background - when highPassFilter is given
        2) normalize magnitude when medianScale is True
        3) normalize magnitude by log transform when logTransform is True

>>>>>>> c1e3ee130d7256ac122fa56c033538dda702739b
    Args
    ----
    dataSetName: input dataset name.

    fov: the field of view to be processed.

    zpos: the z position of the selected FOV to be processed. Each
                  z-plane is preprocessed indepedently.

    warpedImagesName: input file that contains the warped image stack
                  generated by registration.

    outputNameFile: outputName npy file name.
    
    scaleFactorFile: a csv file contains the scaling factor for each
            frame. Each readout image will be normalized by its 
            corresponding scale factor. If scaleFactorFile is None,
            the median intensity value will be used to normalize the 
            intensity of each image.
            
    highPassFilterSigma: the size of the gaussian sigma used in the 
                  high pass filter for removing the cell background.
                  highPassFilterSigma is None, high pass filter will
                  not be performed.
    """

    # print input variables
    print("====== input ======")
    print("dataSetName: %s" % dataSetName)
    print("fov: %d" % fov)
    print("zpos: %f" % zpos)
    print("warpedImagesName: %s" % warpedImagesName)
    print("outputName: %s" % outputName)
    print("highPassFilterSigma: %d" % highPassFilterSigma)
    print("scaleFactorFile: %s" % scaleFactorFile)
    print("logTransform: %r" % logTransform)
    print("==================\n")

    # check points
    utilities.print_checkpoint("Process MERFISH images")
    utilities.print_checkpoint("Start")
    
    # create a zplane object
    zp = zplane.Zplane(dataSetName,
                       fov = fov,
                       zpos = zpos)

    # create the folder
    dirPath = os.path.dirname(outputName)
    os.makedirs(dirPath,
        exist_ok=True)

    # load readout images
    zp.load_warped_images(
        warpedImagesName)
    
    # only kep merfish rounds
    zp.del_frames(
        set(zp.get_readout_name()) - \
        set(zp.get_bit_name()))

    # remove backgroup
    if highPassFilterSigma is not None:
        zp = imagefilter.high_pass_filter(
            obj = zp,
            readoutImage = True,
            fiducialImage = False,
            sigma = highPassFilterSigma)

    # calcualte scale factor
<<<<<<< HEAD
    scaleFactors = preprocessing.estimate_scale_factors(
        obj = zp,
        frameNames = zp.get_readout_name())
    medianValue = np.median([scaleFactors[key] for key in scaleFactors])
    scaleFactors = dict([ (key, value / medianValue) \
                     for key, value in scaleFactors.items() ])
=======
    if scaleFactorFile is None:
        scaleFactors = preprocessing.estimate_scale_factors(
            obj = zp,
            frameNames = zp.get_readout_name())
    else:
        scaleFactors = pd.read_csv(scaleFactorFile)
        scaleFactors = dict(
            zip(scaleFactors.frameName, 
                scaleFactors.value))    
>>>>>>> c1e3ee130d7256ac122fa56c033538dda702739b

    # normalize image intensity
    zp = preprocessing.scale_readout_images(
        obj = zp,
        frameNames = zp.get_bit_name(),
        scaleFactors = scaleFactors)
    
    # low pass filter
    if lowPassFilterSigma is not None:
        zp = imagefilter.low_pass_filter(
            obj = zp,
            frameNames = zp.get_bit_name(),
            sigma = lowPassFilterSigma, 
            windowSize = 3)

    if logTransform is True:
        zp = preprocessing.log_readout_images(
            obj = zp,
            frameNames = zp.get_bit_name())

    # save scale factor
    scaleFactors = pd.DataFrame(scaleFactors.items())
    scaleFactors.columns = ["frameName", "value"]
    prefix = os.path.splitext(outputName)[0]
    scaleFactors.to_csv(
        prefix + "_scale_factor.csv",
        header = True,
        index = False)
    
    np.savez_compressed(
            outputName, 
            zp.get_readout_images())

    # check points
    utilities.print_checkpoint("Done")

def main():
    dataSetName = "191010_LMN7_DIV18_Map2Tau"
    fov = 188
    zpos = 5.0
    warpedImagesName = "warpedImages/fov_188_zpos_5.0.tif"
    outputName = "probImages/fov_188_zpos_5.0.npz"
    highPassFilterSigma = 3
    logTransform = False

    run_job(dataSetName = dataSetName,
            fov = fov,
            zpos = zpos,
            warpedImagesName = warpedImagesName,
            outputName = outputName,
            highPassFilterSigma = highPassFilterSigma,
            logTransform = logTransform)
    
if __name__ == "__main__":
    main()


